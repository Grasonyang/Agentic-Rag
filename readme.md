
# ğŸ¤– Agentic RAG Framework

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python Version](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-%232496ED.svg?style=for-the-badge&logo=docker&logoColor=white)](https://www.docker.com/)
[![Supabase](https://img.shields.io/badge/Supabase-3ECF8E?style=for-the-badge&logo=supabase&logoColor=white)](https://supabase.com/)

**ä¸€å€‹å°ˆç‚ºæ§‹å»ºæ™ºèƒ½ä»£ç†è€Œè¨­è¨ˆçš„ã€å¯æ“´å±•çš„ã€ç”Ÿç”¢ç´šçš„æª¢ç´¢å¢å¼·ç”Ÿæˆ (RAG) æ¡†æ¶ã€‚**

Agentic RAG æ¡†æ¶æä¾›äº†ä¸€å¥—å®Œæ•´çš„å·¥å…·éˆï¼Œå¾ç¶²è·¯æ•¸æ“šçš„è‡ªå‹•çˆ¬å–ã€æ™ºèƒ½è™•ç†ï¼Œåˆ°é«˜æ•ˆçš„å‘é‡åŒ–å­˜å„²å’Œæª¢ç´¢ï¼Œç‚ºé–‹ç™¼å…ˆé€²çš„ AI æ‡‰ç”¨æä¾›äº†å …å¯¦çš„å¾Œç«¯åŸºç¤ã€‚

## ğŸ“‹ é …ç›®æ¦‚è¿°

æœ¬æ¡†æ¶å°ˆç‚ºæ™ºèƒ½ä»£ç†é–‹ç™¼è€Œè¨­è¨ˆï¼Œæ•´åˆäº†ç¶²è·¯çˆ¬èŸ²ã€æ–‡æœ¬è™•ç†ã€å‘é‡å­˜å„²å’Œæ™ºèƒ½æª¢ç´¢åŠŸèƒ½ï¼Œæä¾›ä¼æ¥­ç´šçš„ RAG è§£æ±ºæ–¹æ¡ˆã€‚é€šéæ·±åº¦æ•´åˆ Supabase çš„å¼·å¤§åŠŸèƒ½ï¼Œå¯¦ç¾äº†æ•¸æ“šè™•ç†åˆ°æª¢ç´¢çš„å®Œæ•´é–‰ç’°ã€‚

## ğŸ¯ æ ¸å¿ƒç‰¹æ€§

-   **ğŸŒ æ™ºèƒ½ç¶²è·¯çˆ¬èŸ²**: åŸºæ–¼ `crawl4ai`ï¼Œæ”¯æ´ Sitemap è§£æã€robots.txt éµå¾ªã€ä½µç™¼çˆ¬å–å’Œé©æ‡‰æ€§é€Ÿç‡é™åˆ¶ï¼Œå¯é«˜æ•ˆæŠ“å–å¤§è¦æ¨¡ç¶²ç«™ã€‚
-   **ğŸ§© å½ˆæ€§æ–‡æœ¬è™•ç†**: æä¾›å¤šç¨®æ–‡æœ¬åˆ†å¡Šç­–ç•¥ï¼ˆæ»‘å‹•çª—å£ã€èªç¾©åˆ†å¡Šã€å¥å­åˆ†å¡Šç­‰ï¼‰ï¼Œä¸¦è‡ªå‹•è¨ˆç®—å…§å®¹é›œæ¹Šä»¥å¯¦ç¾å¿«å–å’Œæ•¸æ“šå»é‡ã€‚
-   **ğŸ—„ï¸ é«˜æ•ˆå‘é‡å­˜å„²**: æ·±åº¦æ•´åˆ `Supabase` (PostgreSQL + pgvector)ï¼Œåˆ©ç”¨ HNSW ç´¢å¼•å¯¦ç¾æ¯«ç§’ç´šçš„å‘é‡ç›¸ä¼¼åº¦æœå°‹ã€‚
-   **âš™ï¸ è³‡æ–™åº«å³æœå‹™ (DB as a Service)**: å°‡è¤‡é›œçš„æŸ¥è©¢ã€éæ¿¾å’Œç®¡ç†é‚è¼¯å°è£ç‚ºè³‡æ–™åº«å‡½æ•¸ (RPC)ï¼Œä¸¦é€šé Supabase API å…¬é–‹è¨ªå•ã€‚
-   **ğŸ³ å…¨å®¹å™¨åŒ–éƒ¨ç½²**: ä½¿ç”¨ Docker å’Œ Docker Compose æä¾›ä¸€éµå¼çš„é–‹ç™¼èˆ‡ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²æ–¹æ¡ˆã€‚
-   **âš¡ ç•°æ­¥å„ªå…ˆæ¶æ§‹**: å¾çˆ¬èŸ²åˆ°è³‡æ–™åº«æ“ä½œï¼Œå…¨é¢æ¡ç”¨ç•°æ­¥è¨­è¨ˆï¼Œæœ€å¤§åŒ–ç³»çµ±ååé‡ã€‚
-   **ğŸ›¡ï¸ ä¼æ¥­ç´šè³‡æ–™åº«è¨­è¨ˆ**: çµæ§‹åŒ–çš„ SQL Schemaã€è§¸ç™¼å™¨ã€ç´¢å¼•å’Œå®Œå–„çš„æ¬Šé™ç®¡ç†ï¼Œç¢ºä¿è³‡æ–™çš„å®Œæ•´æ€§èˆ‡å®‰å…¨æ€§ã€‚
-   **ğŸ” Supabase æ¬Šé™ç®¡ç†**: ç‚º `anon` å’Œ `authenticated` è§’è‰²æä¾›ç²¾ç´°åŒ–çš„è¡¨æ ¼å’Œå‡½æ•¸æ¬Šé™ï¼Œç¢ºä¿ API å®‰å…¨è¨ªå•ã€‚

## ğŸ—ï¸ ç³»çµ±æ¶æ§‹

æœ¬æ¡†æ¶æ¡ç”¨æ¨¡çµ„åŒ–è¨­è¨ˆï¼Œä¸»è¦ç”±å…©å¤§å®¹å™¨å”åŒå·¥ä½œï¼Œå¯¦ç¾äº†æ‡‰ç”¨é‚è¼¯èˆ‡æ•¸æ“šå­˜å„²çš„è§£è€¦ã€‚

```mermaid
flowchart TB
 subgraph WorkerCluster["Worker Nodes per domain"]
    direction LR
        WorkerA["Worker Node - siteA.com"]
        WorkerB["Worker Node - siteB.org"]
  end
 subgraph RAGSystem["Agentic RAG System - Master Worker Architecture"]
    direction TB
        Master["Master Node"]
        WorkerCluster
  end
    Crawl4ai["crawl4ai - crawler service"] -. Scraped content .-> Master
    Master -. Send to embed .-> WorkerA & WorkerB
    WorkerA -. Store embeddings .-> Supabase["Supabase (pgvector + API)"]
    WorkerB -. Store embeddings .-> Supabase
    User["User"] -- Query API --> Master
    Master -- Dispatch query --> WorkerA & WorkerB
    WorkerA -- Vector search --> Supabase
    WorkerB -- Vector search --> Supabase
    WorkerA -- Return result --> Master
    WorkerB -- Return result --> Master
    Master -- Final answer --> User

     WorkerA:::Aqua
     WorkerB:::Aqua
     Master:::Rose
     Crawl4ai:::Aqua
     Crawl4ai:::Peach
     User:::Peach
    classDef Rose stroke-width:1px, stroke-dasharray:none, stroke:#FF5978, fill:#FFDFE5, color:#8E2236
    classDef Aqua stroke-width:1px, stroke-dasharray:none, stroke:#46EDC8, fill:#DEFFF8, color:#378E7A
    classDef Peach stroke-width:1px, stroke-dasharray:none, stroke:#FBB35A, fill:#FFEFDB, color:#8F632D

```

### å®¹å™¨åŒ–æ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ‡‰ç”¨å®¹å™¨ (Python)  â”‚    â”‚  Supabase æ•¸æ“šå®¹å™¨   â”‚
â”‚                     â”‚    â”‚   (PostgreSQL)      â”‚
â”‚                     â”‚â—„â”€â”€â–ºâ”‚                     â”‚
â”‚ â€¢ Spider Framework  â”‚    â”‚ â€¢ PostgreSQL 15+    â”‚
â”‚ â€¢ Text Processing   â”‚    â”‚ â€¢ pgvector Extension â”‚
â”‚ â€¢ Embedding Model   â”‚    â”‚ â€¢ RPC Functions      â”‚
â”‚ â€¢ RAG Pipeline      â”‚    â”‚ â€¢ REST API          â”‚
â”‚ â€¢ Rate Limiting     â”‚    â”‚ â€¢ Row Level Security â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
  host.docker.internal      localhost:8000
```

-   **æ‡‰ç”¨å®¹å™¨**: è² è²¬åŸ·è¡Œçˆ¬èŸ²ã€æ–‡æœ¬è™•ç†ã€æ¨¡å‹åµŒå…¥ç­‰è¨ˆç®—å¯†é›†å‹ä»»å‹™ã€‚
-   **æ•¸æ“šå®¹å™¨**: å°ˆè·è² è²¬æ•¸æ“šçš„é«˜æ•ˆå­˜å„²ã€ç´¢å¼•å’Œæª¢ç´¢ï¼Œé€šé Supabase API æä¾›å…¬é–‹è¨ªå•ã€‚

## ğŸ“ é …ç›®çµæ§‹

```
Agentic-Rag/
â”œâ”€â”€ ğŸ“ spider/                 # ç¶²è·¯çˆ¬èŸ²æ¨¡çµ„
â”‚   â”œâ”€â”€ crawlers/              # çˆ¬èŸ²å¯¦ç¾
â”‚   â”‚   â”œâ”€â”€ web_crawler.py     # åŸºæ–¼ crawl4ai çš„é«˜æ€§èƒ½çˆ¬èŸ²
â”‚   â”‚   â”œâ”€â”€ simple_crawler.py  # ç°¡åŒ–ç‰ˆçˆ¬èŸ²ï¼Œæ•´åˆæ•¸æ“šåº«æ“ä½œ
â”‚   â”‚   â”œâ”€â”€ sitemap_parser.py  # Sitemap è§£æå’Œ URL æå–
â”‚   â”‚   â””â”€â”€ fixed_sitemap_parser.py # ä¿®å¾©ç‰ˆ Sitemap è§£æå™¨
â”‚   â”œâ”€â”€ chunking/              # æ–‡æœ¬åˆ†å¡Šç­–ç•¥
â”‚   â”‚   â”œâ”€â”€ base_chunker.py    # åŸºç¤åˆ†å¡Šå™¨æŠ½è±¡é¡
â”‚   â”‚   â”œâ”€â”€ sliding_window.py  # æ»‘å‹•çª—å£åˆ†å¡Šï¼Œä¿æŒä¸Šä¸‹æ–‡
â”‚   â”‚   â”œâ”€â”€ sentence_chunking.py # åŸºæ–¼å¥å­é‚Šç•Œçš„æ™ºèƒ½åˆ†å¡Š
â”‚   â”‚   â”œâ”€â”€ semantic_chunking.py # èªç¾©ç›¸ä¼¼åº¦åˆ†å¡Š (å¯¦é©—æ€§)
â”‚   â”‚   â””â”€â”€ chunker_factory.py # åˆ†å¡Šå™¨å·¥å» æ¨¡å¼
â”‚   â””â”€â”€ utils/                 # å·¥å…·æ¨¡çµ„
â”‚       â”œâ”€â”€ rate_limiter.py    # ä»¤ç‰Œæ¡¶ç®—æ³•é™é€Ÿå™¨
â”‚       â””â”€â”€ retry_manager.py   # æŒ‡æ•¸é€€é¿é‡è©¦æ©Ÿåˆ¶
â”‚   â””â”€â”€ README.md              # Spider æ¨¡çµ„ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ ğŸ“ database/               # è³‡æ–™åº«æ¨¡çµ„
â”‚   â”œâ”€â”€ client.py              # Supabase å®¢æˆ¶ç«¯å°è£
â”‚   â”œâ”€â”€ models.py              # è³‡æ–™æ¨¡å‹å®šç¾©
â”‚   â”œâ”€â”€ operations.py          # è³‡æ–™åº«æ“ä½œå°è£
â”‚   â”œâ”€â”€ manage.py              # è³‡æ–™åº«ç®¡ç†å·¥å…·
â”‚   â”œâ”€â”€ sql/                   # SQL Schema æ–‡ä»¶
â”‚   â”‚   â”œâ”€â”€ schema_all.sql     # å®Œæ•´çš„è³‡æ–™åº« Schema (æ¨è–¦ä½¿ç”¨)
â”‚   â””â”€â”€ README.md              # Database æ¨¡çµ„ä½¿ç”¨æŒ‡å—
â”œâ”€â”€ ğŸ“ scripts/                # å·¥å…·è…³æœ¬
â”œâ”€â”€ ğŸ“ embedding/              # åµŒå…¥æ¨¡å‹æ¨¡çµ„
â”‚   â””â”€â”€ embedding.py           # å‘é‡åµŒå…¥ç®¡ç†å™¨
â”œâ”€â”€ ğŸ“„ config.json.template    # é…ç½®æ–‡ä»¶æ¨¡æ¿
â”œâ”€â”€ ğŸ“„ config_manager.py       # é…ç½®ç®¡ç†å™¨
â”œâ”€â”€ ğŸ“„ ENV_SETUP.md           # ç’°å¢ƒè®Šæ•¸è¨­ç½®æŒ‡å—
â”œâ”€â”€ ğŸ“„ Makefile                # è‡ªå‹•åŒ–æŒ‡ä»¤
â”œâ”€â”€ ğŸ“„ requirements.txt        # Python ä¾è³´æ¸…å–®
â”œâ”€â”€ ğŸ“„ docker-compose.yml      # Docker ç·¨æ’é…ç½®
â””â”€â”€ ğŸ“„ readme.md               # æœ¬æ–‡ä»¶
```

## ğŸš€ å¿«é€Ÿé–‹å§‹

### 1. ç’°å¢ƒé…ç½®

æœ¬é …ç›®å·²ç§»é™¤ .env æ–‡ä»¶ä¾è³´ï¼Œä½¿ç”¨ç’°å¢ƒè®Šæ•¸å’Œ JSON é…ç½®æ–‡ä»¶ï¼š

#### è¨­ç½®å¿…éœ€çš„ç’°å¢ƒè®Šæ•¸ï¼š
```bash
export SUPABASE_URL="your_supabase_url"
export ANON_KEY="your_supabase_anon_key"
export SERVICE_ROLE_KEY="your_supabase_service_role_key"  # å¯é¸
```

#### å¯é¸é…ç½®ï¼š
```bash
export TARGET_URLS="https://example.com,https://example2.com"
export CRAWLER_DELAY=2.5
export CRAWLER_MAX_CONCURRENT=10
```

è©³ç´°è¨­ç½®æŒ‡å—è«‹åƒè€ƒ [ENV_SETUP.md](ENV_SETUP.md)

### 2. å®‰è£ä¾è³´

```bash
pip install -r requirements.txt
```

### 3. æ¸¬è©¦é…ç½®

```bash
python test_no_env.py
```

### 4. é‹è¡Œçˆ¬èŸ²

```bash
# ä½¿ç”¨ make æŒ‡ä»¤ (æ¨è–¦)
make spider

# æˆ–ç›´æ¥é‹è¡Œ
python -m spider.rag_spider
```


## ğŸ’¡ ä½¿ç”¨ç¯„ä¾‹
### ç¶²ç«™çˆ¬èŸ²è…³æœ¬ç¯„ä¾‹

ä»¥ä¸‹è…³æœ¬å¯å”åŠ©è‡ªå‹•åŒ–å¾ `robots.txt` è§£æå¤šå€‹ Sitemapï¼Œä¸¦ä¾ç…§é †åºå°‡çµæœè¨˜éŒ„è‡³è³‡æ–™åº«ï¼š

```bash
# 1. å–å¾— robots.txt ä¸¦è§£ææ‰€æœ‰ Sitemap
python scripts/getSiteMap.py --url https://example.com

# 2. æ ¹æ“š Sitemap ä¾åºæå–æ‰€æœ‰å¯çˆ¬å–çš„ URL
python scripts/getUrls.py --sitemap-list sitemaps.txt

# 3. å°æ¯å€‹ URL é€²è¡Œåˆ†å¡Šè™•ç†
python scripts/getChunking.py --url-list urls.txt

# 4. å°‡åˆ†å¡Šå…§å®¹åµŒå…¥å‘é‡ä¸¦è¨˜éŒ„è‡³è³‡æ–™åº«
python scripts/getEmbedding.py --chunk-list chunks.txt
```

> æ‰€æœ‰è…³æœ¬çš†å¯é…åˆ `make` æŒ‡ä»¤åŸ·è¡Œï¼Œä¾‹å¦‚ï¼š`make get-sitemap`ã€`make get-urls` ç­‰ï¼Œè©³è¦‹ `scripts/` ç›®éŒ„ä¸‹çš„èªªæ˜ã€‚

#### æµç¨‹èªªæ˜

1. **getSiteMap.py**  
  è§£æ robots.txtï¼Œç²å–æ‰€æœ‰ Sitemapï¼Œä¸¦ä¾ robots.txt é †åºè¼¸å‡ºã€‚
2. **getUrls.py**  
  ä¾ç…§ Sitemap é †åºæå– URLï¼Œç¢ºä¿çˆ¬å–é †åºèˆ‡ robots.txt è¨˜éŒ„ä¸€è‡´ã€‚
3. **getChunking.py**  
  å°æ¯å€‹ URL å…§å®¹é€²è¡Œåˆ†å¡Šï¼Œä¾¿æ–¼å¾ŒçºŒåµŒå…¥èˆ‡å„²å­˜ã€‚
4. **getEmbedding.py**  
  å°‡åˆ†å¡Šå…§å®¹åµŒå…¥å‘é‡ï¼Œä¸¦ä¾é †åºå¯«å…¥è³‡æ–™åº«ï¼Œæ–¹ä¾¿æª¢ç´¢èˆ‡è¿½è¹¤ã€‚

> æ‰€æœ‰æ­¥é©Ÿå‡å¯è‡ªå‹•åŒ–ä¸²æ¥ï¼Œç¢ºä¿è³‡æ–™æµèˆ‡é †åºèˆ‡åŸå§‹ robots.txt/Sitemap è¨˜éŒ„ä¸€è‡´ã€‚


## ğŸ“Š ç›£æ§èˆ‡æ•ˆèƒ½


## ğŸš€ éƒ¨ç½²æŒ‡å—


## ğŸ¤ è²¢ç»æŒ‡å—

æ­¡è¿è²¢ç»ï¼è«‹éµå¾ªä»¥ä¸‹æ­¥é©Ÿï¼š

1. **Fork å°ˆæ¡ˆ**
2. **å‰µå»ºåŠŸèƒ½åˆ†æ”¯** (`git checkout -b feature/amazing-feature`)
3. **æäº¤è®Šæ›´** (`git commit -m 'Add amazing feature'`)
4. **æ¨é€åˆ°åˆ†æ”¯** (`git push origin feature/amazing-feature`)
5. **é–‹å•Ÿ Pull Request**

### ç¨‹å¼ç¢¼é¢¨æ ¼
- ä½¿ç”¨ `black` æ ¼å¼åŒ– Python ç¨‹å¼ç¢¼
- éµå¾ª PEP 8 é¢¨æ ¼æŒ‡å—
- ç‚ºæ–°åŠŸèƒ½æ·»åŠ é©ç•¶çš„æ¸¬è©¦
- æ›´æ–°ç›¸é—œæ–‡ä»¶

## ğŸ“„ æˆæ¬Šæ¢æ¬¾

æœ¬å°ˆæ¡ˆæ¡ç”¨ MIT æˆæ¬Šæ¢æ¬¾ - è©³è¦‹ [LICENSE](LICENSE) æ–‡ä»¶

## ğŸ†˜ æ”¯æ´èˆ‡å•é¡Œå›å ±

- **å•é¡Œå›å ±**: [GitHub Issues](https://github.com/your-username/agentic-rag/issues)
- **åŠŸèƒ½å»ºè­°**: [GitHub Discussions](https://github.com/your-username/agentic-rag/discussions)
- **æ–‡ä»¶å•é¡Œ**: æ­¡è¿ç›´æ¥æäº¤ PR æ”¹å–„

