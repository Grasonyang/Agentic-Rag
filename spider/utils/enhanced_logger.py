"""
å¢å¼·çš„æ—¥èªŒè¨˜éŒ„ç³»çµ±
æ”¯æ´çµæ§‹åŒ–æ—¥èªŒã€éŒ¯èª¤è¿½è¹¤å’Œæ€§èƒ½ç›£æ§
"""

import logging
import logging.handlers
import json
import time
import traceback
from typing import Dict, Any, Optional
from datetime import datetime
from pathlib import Path
import os


class StructuredFormatter(logging.Formatter):
    """çµæ§‹åŒ–æ—¥èªŒæ ¼å¼å™¨"""
    
    def format(self, record):
        log_data = {
            "timestamp": datetime.fromtimestamp(record.created).isoformat(),
            "level": record.levelname,
            "logger": record.name,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
            "line": record.lineno
        }
        
        # æ·»åŠ é¡å¤–çš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        if hasattr(record, 'url'):
            log_data['url'] = record.url
        if hasattr(record, 'status_code'):
            log_data['status_code'] = record.status_code
        if hasattr(record, 'duration'):
            log_data['duration'] = record.duration
        if hasattr(record, 'error_type'):
            log_data['error_type'] = record.error_type
        if hasattr(record, 'retry_count'):
            log_data['retry_count'] = record.retry_count
            
        # å¦‚æœæ˜¯ç•°å¸¸è¨˜éŒ„ï¼Œæ·»åŠ è©³ç´°çš„ç•°å¸¸ä¿¡æ¯
        if record.exc_info:
            log_data['exception'] = {
                "type": record.exc_info[0].__name__,
                "message": str(record.exc_info[1]),
                "traceback": traceback.format_exception(*record.exc_info)
            }
        
        return json.dumps(log_data, ensure_ascii=False)


class SpiderLogger:
    """çˆ¬èŸ²å°ˆç”¨æ—¥èªŒè¨˜éŒ„å™¨"""
    
    def __init__(self, name: str = "rag_spider", log_dir: str = "logs"):
        self.name = name
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # å‰µå»ºlogger
        self.logger = logging.getLogger(name)
        self.logger.setLevel(logging.DEBUG)
        
        # é¿å…é‡è¤‡æ·»åŠ handler
        if not self.logger.handlers:
            self._setup_handlers()
        
        # çµ±è¨ˆä¿¡æ¯
        self.stats = {
            "requests_total": 0,
            "requests_success": 0,
            "requests_failed": 0,
            "total_duration": 0.0,
            "errors_by_type": {},
            "start_time": time.time()
        }
    
    def _setup_handlers(self):
        """è¨­ç½®æ—¥èªŒè™•ç†å™¨"""
        
        # 1. æ§åˆ¶å°è™•ç†å™¨ - ç°¡æ½”æ ¼å¼
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        console_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        console_handler.setFormatter(console_formatter)
        
        # 2. æ–‡ä»¶è™•ç†å™¨ - è©³ç´°æ ¼å¼
        file_handler = logging.handlers.RotatingFileHandler(
            self.log_dir / f"{self.name}.log",
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )
        file_handler.setLevel(logging.DEBUG)
        file_formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(module)s:%(funcName)s:%(lineno)d - %(message)s'
        )
        file_handler.setFormatter(file_formatter)
        
        # 3. çµæ§‹åŒ–æ—¥èªŒè™•ç†å™¨ - JSONæ ¼å¼
        structured_handler = logging.handlers.RotatingFileHandler(
            self.log_dir / f"{self.name}_structured.log",
            maxBytes=10*1024*1024,  # 10MB
            backupCount=5
        )
        structured_handler.setLevel(logging.DEBUG)
        structured_handler.setFormatter(StructuredFormatter())
        
        # 4. éŒ¯èª¤æ—¥èªŒè™•ç†å™¨ - åªè¨˜éŒ„éŒ¯èª¤
        error_handler = logging.handlers.RotatingFileHandler(
            self.log_dir / f"{self.name}_errors.log",
            maxBytes=5*1024*1024,  # 5MB
            backupCount=3
        )
        error_handler.setLevel(logging.ERROR)
        error_handler.setFormatter(file_formatter)
        
        # æ·»åŠ è™•ç†å™¨
        self.logger.addHandler(console_handler)
        self.logger.addHandler(file_handler)
        self.logger.addHandler(structured_handler)
        self.logger.addHandler(error_handler)
    
    def log_request_start(self, url: str, method: str = "GET") -> Dict[str, Any]:
        """è¨˜éŒ„è«‹æ±‚é–‹å§‹"""
        context = {
            "url": url,
            "method": method,
            "start_time": time.time(),
            "request_id": f"{int(time.time() * 1000)}"
        }
        
        self.logger.info(
            f"ğŸš€ é–‹å§‹è«‹æ±‚: {method} {url}",
            extra={"url": url, "request_id": context["request_id"]}
        )
        
        self.stats["requests_total"] += 1
        return context
    
    def log_request_success(self, context: Dict[str, Any], status_code: int = 200, 
                          content_length: int = 0):
        """è¨˜éŒ„è«‹æ±‚æˆåŠŸ"""
        duration = time.time() - context["start_time"]
        
        self.logger.info(
            f"âœ… è«‹æ±‚æˆåŠŸ: {context['url']} ({status_code}) - {duration:.2f}s - {content_length} bytes",
            extra={
                "url": context["url"],
                "status_code": status_code,
                "duration": duration,
                "content_length": content_length,
                "request_id": context["request_id"]
            }
        )
        
        self.stats["requests_success"] += 1
        self.stats["total_duration"] += duration
    
    def log_request_error(self, context: Dict[str, Any], error: Exception, 
                         status_code: Optional[int] = None, retry_count: int = 0):
        """è¨˜éŒ„è«‹æ±‚éŒ¯èª¤"""
        duration = time.time() - context["start_time"]
        error_type = type(error).__name__
        
        self.logger.error(
            f"âŒ è«‹æ±‚å¤±æ•—: {context['url']} - {error_type}: {str(error)} (é‡è©¦: {retry_count})",
            extra={
                "url": context["url"],
                "error_type": error_type,
                "status_code": status_code,
                "duration": duration,
                "retry_count": retry_count,
                "request_id": context["request_id"]
            },
            exc_info=True
        )
        
        self.stats["requests_failed"] += 1
        self.stats["total_duration"] += duration
        
        # çµ±è¨ˆéŒ¯èª¤é¡å‹
        if error_type not in self.stats["errors_by_type"]:
            self.stats["errors_by_type"][error_type] = 0
        self.stats["errors_by_type"][error_type] += 1
    
    def log_database_operation(self, operation: str, table: str, success: bool, 
                             count: int = 0, error: Optional[Exception] = None):
        """è¨˜éŒ„è³‡æ–™åº«æ“ä½œ"""
        if success:
            self.logger.info(
                f"ğŸ’¾ è³‡æ–™åº«æ“ä½œæˆåŠŸ: {operation} {table} ({count} æ¢è¨˜éŒ„)",
                extra={"operation": operation, "table": table, "count": count}
            )
        else:
            self.logger.error(
                f"ğŸ’¥ è³‡æ–™åº«æ“ä½œå¤±æ•—: {operation} {table} - {str(error)}",
                extra={"operation": operation, "table": table, "error_type": type(error).__name__},
                exc_info=True
            )
    
    def log_sitemap_parsing(self, sitemap_url: str, urls_found: int, success: bool, 
                           error: Optional[Exception] = None):
        """è¨˜éŒ„ sitemap è§£æ"""
        if success:
            self.logger.info(
                f"ğŸ—ºï¸ Sitemap è§£ææˆåŠŸ: {sitemap_url} ({urls_found} å€‹ URLs)",
                extra={"url": sitemap_url, "urls_found": urls_found}
            )
        else:
            self.logger.error(
                f"ğŸ—ºï¸ Sitemap è§£æå¤±æ•—: {sitemap_url} - {str(error)}",
                extra={"url": sitemap_url, "error_type": type(error).__name__},
                exc_info=True
            )
    
    def log_content_extraction(self, url: str, title: str, content_length: int, 
                             success: bool, error: Optional[Exception] = None):
        """è¨˜éŒ„å…§å®¹æå–"""
        if success:
            self.logger.info(
                f"ğŸ“„ å…§å®¹æå–æˆåŠŸ: {url} - '{title}' ({content_length} å­—ç¬¦)",
                extra={"url": url, "title": title, "content_length": content_length}
            )
        else:
            self.logger.error(
                f"ğŸ“„ å…§å®¹æå–å¤±æ•—: {url} - {str(error)}",
                extra={"url": url, "error_type": type(error).__name__},
                exc_info=True
            )
    
    def log_chunking(self, url: str, chunks_created: int, chunk_method: str):
        """è¨˜éŒ„å…§å®¹åˆ†å¡Š"""
        self.logger.info(
            f"ğŸ”ª å…§å®¹åˆ†å¡Šå®Œæˆ: {url} - {chunks_created} å€‹å¡Š ({chunk_method})",
            extra={"url": url, "chunks_created": chunks_created, "chunk_method": chunk_method}
        )
    
    def log_retry_attempt(self, url: str, attempt: int, max_attempts: int, 
                         reason: str, delay: float):
        """è¨˜éŒ„é‡è©¦å˜—è©¦"""
        self.logger.warning(
            f"ğŸ”„ é‡è©¦å˜—è©¦ {attempt}/{max_attempts}: {url} - {reason} (å»¶é²: {delay:.2f}s)",
            extra={"url": url, "retry_count": attempt, "max_retries": max_attempts, 
                  "retry_reason": reason, "delay": delay}
        )
    
    def log_rate_limit(self, url: str, retry_after: Optional[float] = None):
        """è¨˜éŒ„é€Ÿç‡é™åˆ¶"""
        message = f"â³ è§¸ç™¼é€Ÿç‡é™åˆ¶: {url}"
        if retry_after:
            message += f" (å»ºè­°ç­‰å¾…: {retry_after}s)"
        
        self.logger.warning(
            message,
            extra={"url": url, "rate_limited": True, "retry_after": retry_after}
        )
    
    def log_statistics(self):
        """è¨˜éŒ„çµ±è¨ˆä¿¡æ¯"""
        runtime = time.time() - self.stats["start_time"]
        success_rate = (self.stats["requests_success"] / max(self.stats["requests_total"], 1)) * 100
        avg_duration = self.stats["total_duration"] / max(self.stats["requests_success"], 1)
        
        stats_message = (
            f"ğŸ“Š çˆ¬èŸ²çµ±è¨ˆ - "
            f"é‹è¡Œæ™‚é–“: {runtime:.1f}s, "
            f"ç¸½è«‹æ±‚: {self.stats['requests_total']}, "
            f"æˆåŠŸ: {self.stats['requests_success']}, "
            f"å¤±æ•—: {self.stats['requests_failed']}, "
            f"æˆåŠŸç‡: {success_rate:.1f}%, "
            f"å¹³å‡éŸ¿æ‡‰æ™‚é–“: {avg_duration:.2f}s"
        )
        
        self.logger.info(stats_message, extra={"stats": self.stats})
        
        # è¨˜éŒ„éŒ¯èª¤é¡å‹åˆ†å¸ƒ
        if self.stats["errors_by_type"]:
            for error_type, count in self.stats["errors_by_type"].items():
                self.logger.info(f"  éŒ¯èª¤é¡å‹ {error_type}: {count} æ¬¡")
    
    def get_stats(self) -> Dict[str, Any]:
        """ç²å–çµ±è¨ˆä¿¡æ¯"""
        runtime = time.time() - self.stats["start_time"]
        success_rate = (self.stats["requests_success"] / max(self.stats["requests_total"], 1)) * 100
        avg_duration = self.stats["total_duration"] / max(self.stats["requests_success"], 1)
        
        return {
            **self.stats,
            "runtime": runtime,
            "success_rate": success_rate,
            "avg_duration": avg_duration
        }
    
    def info(self, message: str, **kwargs):
        """ä¿¡æ¯æ—¥èªŒ"""
        self.logger.info(message, extra=kwargs)
    
    def warning(self, message: str, **kwargs):
        """è­¦å‘Šæ—¥èªŒ"""
        self.logger.warning(message, extra=kwargs)
    
    def error(self, message: str, **kwargs):
        """éŒ¯èª¤æ—¥èªŒ"""
        self.logger.error(message, extra=kwargs)
    
    def debug(self, message: str, **kwargs):
        """èª¿è©¦æ—¥èªŒ"""
        self.logger.debug(message, extra=kwargs)


# å…¨å±€æ—¥èªŒè¨˜éŒ„å™¨å¯¦ä¾‹
spider_logger = SpiderLogger()

# ä¾¿æ·å‡½æ•¸
def get_spider_logger(name: str = "rag_spider") -> SpiderLogger:
    """ç²å–çˆ¬èŸ²æ—¥èªŒè¨˜éŒ„å™¨"""
    return SpiderLogger(name)
