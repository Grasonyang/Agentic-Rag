# Makefile for Agentic RAG System Database Management

.PHONY: db-check db-status db-fresh db-clear db-form db-tables db-fresh-force db-clear-force
.PHONY: logs-show logs-clean output-show help install test spider-run db-test
.PHONY: get-sitemap get-urls get-chunking get-embedding run-workflow

# Default goal
.DEFAULT_GOAL := help

# Variables for workflow
URL ?= https://example.com
SITEMAP_LIST ?= sitemaps.txt
URL_LIST ?= urls.txt
MAX_URLS ?= 1000
CHUNK_SIZE ?= 200

db-check:
	python3 scripts/database/make-db-check.py

db-status:
	@echo 'ğŸ” å¿«é€Ÿè³‡æ–™åº«ç‹€æ…‹æª¢æŸ¥...'
	@python3 -c "import sys; sys.path.append('.'); from database.postgres_client import PostgreSQLClient; client = PostgreSQLClient(); client.connect(); print('âœ… è³‡æ–™åº«é€£æ¥æ­£å¸¸'); client.disconnect()" 2>/dev/null || echo 'âŒ è³‡æ–™åº«é€£æ¥å¤±æ•—'

db-fresh:
	@echo "ğŸ”„ é‡æ–°åˆå§‹åŒ–è³‡æ–™åº«..."
	@python3 scripts/database/make-fresh.py

db-clear:
	python3 scripts/database/make-clear.py

# Additional database commands
db-form:
	@echo "ğŸ“„ ç²å–è³‡æ–™åº«è¡¨å–®æ•¸æ“š..."
	@python3 scripts/database/make-db-check.py | grep -A 1000 "è³‡æ–™åº«è¡¨å–® JSON æ•¸æ“š:" | tail -n +3

db-tables:
	@echo "ğŸ“‹ è³‡æ–™åº«è¡¨æ ¼ä¿¡æ¯..."
	@python3 -c "import sys; sys.path.append('.'); from database.postgres_client import PostgreSQLClient; client = PostgreSQLClient(); client.connect(); tables = ['discovered_urls', 'articles', 'article_chunks', 'sitemaps']; [print(f'ğŸ“Š {table}: {client.get_table_count(table) if client.table_exists(table) else \"ä¸å­˜åœ¨\"} ç­†è¨˜éŒ„') for table in tables]; client.disconnect()"

db-fresh-force:
	@echo "ğŸ”¥ å¼·åˆ¶é‡æ–°åˆå§‹åŒ–è³‡æ–™åº«..."
	@python3 scripts/database/make-fresh.py --force

db-clear-force:
	@echo "ğŸ”¥ å¼·åˆ¶æ¸…ç©ºè³‡æ–™åº«æ•¸æ“š..."
	@python3 scripts/database/make-clear.py --force

# Utility commands
logs-show:
	@echo "ğŸ“‹ æœ€è¿‘çš„è…³æœ¬æ—¥èªŒ:"
	@ls -la scripts/logs/ 2>/dev/null | tail -10 || echo "æ²’æœ‰æ—¥èªŒç›®éŒ„"

logs-clean:
	@echo "ğŸ§¹ æ¸…ç†èˆŠæ—¥èªŒæ–‡ä»¶..."
	@find scripts/logs -name "*.log" -mtime +7 -delete 2>/dev/null || true
	@echo "âœ… æ—¥èªŒæ¸…ç†å®Œæˆ"

output-show:
	@echo "ğŸ“ æœ€è¿‘ç”Ÿæˆçš„è¼¸å‡ºæ–‡ä»¶:"
	@ls -la scripts/output/ 2>/dev/null | tail -10 || echo "æ²’æœ‰è¼¸å‡ºæ–‡ä»¶"

help:
	@echo "å¯ç”¨çš„è³‡æ–™åº«æŒ‡ä»¤:"
	@echo "  db-check        - åŸ·è¡Œå®Œæ•´çš„è³‡æ–™åº«å¥åº·æª¢æŸ¥"
	@echo "  db-status       - å¿«é€Ÿè³‡æ–™åº«ç‹€æ…‹æª¢æŸ¥"
	@echo "  db-fresh        - é‡æ–°åˆå§‹åŒ–è³‡æ–™åº«"
	@echo "  db-fresh-force  - å¼·åˆ¶é‡æ–°åˆå§‹åŒ–è³‡æ–™åº«"
	@echo "  db-clear        - æ¸…ç©ºè³‡æ–™åº«æ•¸æ“š"
	@echo "  db-clear-force  - å¼·åˆ¶æ¸…ç©ºè³‡æ–™åº«æ•¸æ“š"
	@echo "  db-form         - ç²å–è³‡æ–™åº«è¡¨å–®æ•¸æ“š (JSON)"
	@echo "  db-tables       - é¡¯ç¤ºè³‡æ–™åº«è¡¨æ ¼ä¿¡æ¯"
	@echo ""
	@echo "RAG å·¥ä½œæµç¨‹æŒ‡ä»¤:"
	@echo "  get-sitemap     - ç²å–ç¶²ç«™ Sitemap åˆ—è¡¨"
	@echo "  get-urls        - å¾ Sitemap æå– URL"
	@echo "  get-chunking    - çˆ¬å–å…§å®¹ä¸¦åˆ†å¡Š"
	@echo "  get-embedding   - ç”ŸæˆåµŒå…¥å‘é‡"
	@echo "  run-workflow    - åŸ·è¡Œå®Œæ•´ RAG æµç¨‹"
	@echo ""
	@echo "ä½¿ç”¨ç¯„ä¾‹:"
	@echo "  make run-workflow URL=https://docs.python.org"
	@echo "  make get-sitemap URL=https://example.com"
	@echo "  make get-urls SITEMAP_LIST=sitemaps.txt MAX_URLS=500"
	@echo ""
	@echo "æ—¥èªŒå’Œç¶­è­·æŒ‡ä»¤:"
	@echo "  logs-show       - é¡¯ç¤ºæœ€è¿‘çš„æ—¥èªŒ"
	@echo "  logs-clean      - æ¸…ç†èˆŠæ—¥èªŒæ–‡ä»¶"
	@echo "  output-show     - é¡¯ç¤ºæœ€è¿‘çš„è¼¸å‡ºæ–‡ä»¶"
	@echo ""
	@echo "é …ç›®è¨­ç½®æŒ‡ä»¤:"
	@echo "  install         - å®‰è£ Python ä¾è³´"
	@echo "  test            - é‹è¡Œæ¸¬è©¦"
	@echo "  spider-run      - é‹è¡Œçˆ¬èŸ²æ¸¬è©¦"
	@echo "  db-test         - æ¸¬è©¦è³‡æ–™åº«å®Œæ•´æµç¨‹"

# Project setup commands
install:
	@echo "ğŸ“¦ å®‰è£ Python ä¾è³´..."
	@pip3 install -r requirements.txt
	@echo "âœ… ä¾è³´å®‰è£å®Œæˆ"

test:
	@echo "ğŸ§ª é‹è¡Œæ¸¬è©¦..."
	@python3 -m pytest scripts/database/test_db_check.py -v
	@echo "âœ… æ¸¬è©¦å®Œæˆ"

spider-run:
	@echo "ğŸ•·ï¸ é‹è¡Œçˆ¬èŸ²æ¸¬è©¦..."
	@python3 -c "import sys; sys.path.append('.'); from spider.rag_spider import RAGSpider; spider = RAGSpider(); print('ğŸš€ çˆ¬èŸ²åˆå§‹åŒ–æˆåŠŸ')"

# Database testing command
db-test:
	@echo "ğŸ§ª æ¸¬è©¦è³‡æ–™åº«å®Œæ•´æµç¨‹..."
	@echo "1ï¸âƒ£ æª¢æŸ¥è³‡æ–™åº«ç‹€æ…‹..."
	@make db-status
	@echo "2ï¸âƒ£ åŸ·è¡Œå¥åº·æª¢æŸ¥..."
	@make db-check > /dev/null
	@echo "3ï¸âƒ£ é¡¯ç¤ºè¡¨æ ¼ä¿¡æ¯..."
	@make db-tables
	@echo "âœ… è³‡æ–™åº«æ¸¬è©¦å®Œæˆï¼"

# RAG Workflow Commands
get-sitemap:
	@echo "ğŸ—ºï¸ ç²å– Sitemap åˆ—è¡¨..."
	@echo "ç›®æ¨™ç¶²ç«™: $(URL)"
	@python3 -c "import sys; sys.path.append('.'); from spider.rag_spider import discover_sitemaps; discover_sitemaps('$(URL)', '$(SITEMAP_LIST)')"

# ä½¿ç”¨ .env ä¸­çš„ TARGET_URLS é€²è¡Œå®Œæ•´å·¥ä½œæµç¨‹
run-env-workflow:
	@echo "ğŸš€ ä½¿ç”¨ .env è¨­å®šåŸ·è¡Œ RAG å·¥ä½œæµç¨‹..."
	@echo "====================================="
	@python3 -c "import os; from dotenv import load_dotenv; load_dotenv(); print(f'ç›®æ¨™ URLs: {os.getenv(\"TARGET_URLS\", \"æœªè¨­å®š\")}')"
	@echo "====================================="
	@echo ""
	@echo "æ­¥é©Ÿ 1: å¾ .env è®€å–ä¸¦ç™¼ç¾ Sitemap"
	@python3 -c "import sys, os; sys.path.append('.'); from dotenv import load_dotenv; load_dotenv(); from spider.rag_spider import discover_sitemaps; target_urls = os.getenv('TARGET_URLS', ''); [discover_sitemaps(url.strip(), 'sitemaps.txt') for url in target_urls.split(',') if url.strip()]"
	@echo ""
	@echo "æ­¥é©Ÿ 2: æå– URL"
	@make get-urls SITEMAP_LIST=$(SITEMAP_LIST) MAX_URLS=$(MAX_URLS)
	@echo ""
	@echo "æ­¥é©Ÿ 3: çˆ¬å–å’Œåˆ†å¡Š"
	@make get-chunking URL_LIST=$(URL_LIST) CHUNK_SIZE=$(CHUNK_SIZE)
	@echo ""
	@echo "æ­¥é©Ÿ 4: ç”ŸæˆåµŒå…¥"
	@make get-embedding
	@echo ""
	@echo "âœ… RAG å·¥ä½œæµç¨‹å®Œæˆï¼"
	@make db-tables

get-urls:
	@echo "ğŸ”— å¾ Sitemap æå– URL åˆ—è¡¨..."
	@echo "Sitemap æ¸…å–®: $(SITEMAP_LIST)"
	@echo "æœ€å¤§ URL æ•¸: $(MAX_URLS)"
	@python3 -c "import sys; sys.path.append('.'); from spider.rag_spider import extract_urls_from_sitemaps; extract_urls_from_sitemaps('$(SITEMAP_LIST)', '$(URL_LIST)', $(MAX_URLS))"

get-chunking:
	@echo "ğŸ“„ çˆ¬å–ç¶²é å…§å®¹ä¸¦é€²è¡Œåˆ†å¡Š..."
	@echo "URL æ¸…å–®: $(URL_LIST)"
	@echo "å¡Šå¤§å°: $(CHUNK_SIZE)"
	@python3 -c "import sys; sys.path.append('.'); from spider.rag_spider import crawl_and_chunk_urls; crawl_and_chunk_urls('$(URL_LIST)', $(CHUNK_SIZE))"

get-embedding:
	@echo "ğŸ§  ç”Ÿæˆå…§å®¹åµŒå…¥å‘é‡..."
	@python3 -c "import sys; sys.path.append('.'); print('âš ï¸ åµŒå…¥åŠŸèƒ½é–‹ç™¼ä¸­...')"

run-workflow:
	@echo "ğŸš€ åŸ·è¡Œå®Œæ•´ RAG å·¥ä½œæµç¨‹..."
	@echo "====================================="
	@echo "ç›®æ¨™ç¶²ç«™: $(URL)"
	@echo "====================================="
	@echo ""
	@echo "æ­¥é©Ÿ 1: ç™¼ç¾ Sitemap"
	@make get-sitemap URL=$(URL)
	@echo ""
	@echo "æ­¥é©Ÿ 2: æå– URL"
	@make get-urls SITEMAP_LIST=$(SITEMAP_LIST) MAX_URLS=$(MAX_URLS)
	@echo ""
	@echo "æ­¥é©Ÿ 3: çˆ¬å–å’Œåˆ†å¡Š"
	@make get-chunking URL_LIST=$(URL_LIST) CHUNK_SIZE=$(CHUNK_SIZE)
	@echo ""
	@echo "æ­¥é©Ÿ 4: ç”ŸæˆåµŒå…¥"
	@make get-embedding
	@echo ""
	@echo "âœ… RAG å·¥ä½œæµç¨‹å®Œæˆï¼"
	@make db-tables
